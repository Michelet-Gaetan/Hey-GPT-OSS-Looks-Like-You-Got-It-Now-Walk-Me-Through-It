# Text generation

This folder contaions all the elements used to generate the texts that are then evaluated for the experiment.

## Data

### ./data/
This folder contains the files used to create the prompt and the role for each task. They are each time divided throughout 5 files:

- context.txt: provides the context to the model
- input.txt: provides the input data to the model and explains its format
- instruction.txt: provides the request to the model
- output_format.txt: provides more indication about the model's answer
- role.txt: provides the role that the model will take

log-file-analysis (BHA), suspicious-message-detection (SMD), and timeline analysis (TA) used specific input data.

#### ./data/log-file-analsis/data/
For the log analysis, a bash history was generated using ChatGPT. The whole discussion with the chat model, generating harmless and suspicious elements, can be found in gpt_generation.txt. Then the different parts were concatenated and adjusted: the ip was changed from aaa.bbb.ccc.ddd to 100.200.30.40, incoherent urls were adapted, nonsense searchploits were removed, and repetitivity was reduced. The result is in bash_history.txt.

#### ./data/suspicious-message-detection/data/
For this task, a chat was generated using ChatGPT. The discussion with ChatGPT can be found in prompts.txt. The chat was then extracted and stored in chat.txt.

#### ./data/timeline-analysis/data/
For this task a manually created timeline was used. The data was then filtered on the day of interest, filtered on events that are considered relevant using zimmerman timeline explorer (colored events), and useless columns were removed. All the files are there, and the process is described in process.txt. In the end, the winxp-filter-columns-zimmerman-short.csv was used as input data.

### ./data_redo/
We realized that some of the prompts could be improved between the first run and the evaluation. We decided to rerun our script for two tasks: suspicious-message-detection and methodology-generation. For the methodology-generation, the questions asked to the investigator were changed, and the 4-phases NIST model was provided as a basis to help generating a more specific methodology.

#### ./data_redo/suspicious-message-detection/data/
The text was adjusted to remove any direct mention to the breaking bad show, which would make the task to easy for the model.

### ./output/final/
This is the folder in which the texts generated by the model were saved. The name of the task is included in the name of the files. There are 4 versions for each file:

- temp file: used to save progress now and then in case of crash during program execution
- prompt file: used to save the prompt and role used for each task
- timestamped file: final file for each task, the timestamp corresponds to the end of the process
- timestamped_new file: final version of the file with the different parts of the generated texts separated (namely the prompt, reasoning part, and the final answer)

### ./output/final/redo/
Exact same as ./output/final/, but for the two tasks that were redone.

## Code

### ./main.py
This python file was used to generate the text. It start by creating the prompt and role for each task. Then, for each task and for each reasoning level, it then loads the gpt-oss-20b, apply the chat template using the appropriate prompt, role, and reasoning level, generates the 6 texts (4 times with sampling and a temperature of 0.7 and 2 times without sampling), and saves the decoded texts. Note that some other elements were gathered such as the id of the last token (to determine if the generation stopped due to the stop token or the max number of tokens), the duration of the generation, and the number of tokens generated.

Note that later only one of the two texte generated without sampling is evaluated as they are both the same.

The input of this code is ./data/, and the output are the temp files, the prompt files, and the timestamped files in ./output/final/.

### ./main_redo.py
Exact same as ./main.py but this time for the tasks that were redone. 

The input of this code is ./data_redo/, and the output are the temp files, the prompt files, and the timestamped files in ./output/final/redo/.

### ./check_no_sampling.py
This python file was used to automatically check that the generation process was done correctly. It checks for each task/reasoning combination that the texts generated with sampling are different and that the texts generated without sampling are the same.

The input for this code are the timestamped files in ./output/final/redo/ and ./output/final/.

### ./output/final/divide_generated.py
This python file was used to separate the different elements from the generated text: the prompt, the reasoning, and the final answer. The number of token is also computed for each of these parts.

The input of this code are the timestamped files in ./output/final/, and the output are the timestamped_new files in ./output/final/.

### ./output/final/redo/divide_generated.py
Exact same as ./output/final/divide_generated.py but this time for the tasks that were redone.

The input of this code are the timestamped files in ./output/final/redo/, and the output are the timestamped_new files in ./output/final/redo/.

## Data considered during the evaluation
As explained, some tasks had to be redone. We also used the timestamped_new versions of the files as the reasoning and final answers are already isolated (and they also contain more info). Therefore, the 4 following files were used during the evaluation:

- ./output/final/output_log-file-analysis_2025_09_26__03_40_56_new.txt
- ./output/final/output_timeline-analysis_2025_09_25__23_30_48_new.txt
- ./output/final/redo/output_methodology-generation_2025_09_29__18_25_44_new.txt
- ./output/final/redo/output_suspicious-message-detection_2025_09_29__16_22_56_new.txt



